# ğŸ Experiment 4: Ensemble Learning for SMS Spam Classification Using Voting, Stacking, and AdaBoost

---

# ğŸ¯ Project Objective

The objective of this project is to implement and compare multiple classifier combination techniques for SMS spam detection. The project evaluates individual base learners and ensemble strategies including Hard Voting, Soft Voting, Stacking, and AdaBoost with decision stumps using Stratified K-Fold Cross Validation.

---

# ğŸ“„ Problem Statement  

A messaging platform wants to automatically classify SMS messages as **Spam** or **Ham (Not Spam)**.

The goal is to:

- Train individual machine learning classifiers  
- Combine classifiers using ensemble techniques  
- Implement AdaBoost using decision stumps (max_depth = 1)  
- Compare performance using Precision, Recall, F1-score, ROC-AUC  
- Recommend the best combining strategy  

---

# ğŸ“Š Dataset Description  

Dataset used: SMS Spam Collection (UCI Dataset ID: 228)

This dataset contains 5,574 SMS messages labeled as spam or ham.

Each record consists of:
- Label (ham or spam)  
- Message text  

---

# ğŸ¯ Target Variable  

**label**

- 0 â†’ Ham  
- 1 â†’ Spam  

---

# ğŸ“ Folder Contents  

```
Spam-Ensemble-Project
 â”£ task4_spam_ensemble_combination.py
 â”£ sms.csv
 â”£ ensemble_comparison.csv
 â”£ final_model_predictions.csv
 â”£ README.md
```

---

# ğŸ“¥ Input Features  

| Feature  |   Description    |
|----------|------------------|
| message  | SMS text content |

Text is converted into numerical format using **TF-IDF vectorization**.

---

# ğŸ›  Tools & Technologies  

- Python  
- Scikit-learn  
- Pandas  
- NumPy  
- TF-IDF Vectorizer  
- Google Colab  

---

# âš™ Methodology  

## 1ï¸âƒ£ Data Preprocessing  
- Convert dataset to CSV format  
- Label Encoding (ham=0, spam=1)  
- TF-IDF Vectorization  

## 2ï¸âƒ£ Base Learners  
- Multinomial Naive Bayes  
- Logistic Regression  
- Linear SVM  

## 3ï¸âƒ£ Ensemble Methods  
- Hard Voting  
- Soft Voting  
- Stacking (Meta-Learner: Logistic Regression)  
- AdaBoost with Decision Stumps (max_depth=1)  

## 4ï¸âƒ£ Evaluation Strategy  
- Stratified 5-Fold Cross Validation  
- Metrics:
  - Precision  
  - Recall  
  - F1-score  
  - ROC-AUC  
- Confusion Matrix  

---

# ğŸ“ˆ Results & Insights  

Key Observations:

- Logistic Regression and Linear SVM performed strongly as individual models.
- Hard Voting improved stability but ignored probability information.
- Soft Voting performed better than Hard Voting.
- Stacking provided better generalization by learning optimal combination weights.
- AdaBoost with stumps improved weak learners but was slightly less effective on high-dimensional TF-IDF features.

---

### ğŸ”¥ Best Performing Model:
**Stacking Classifier**

It achieved the highest F1-score and ROC-AUC with stable cross-validation performance.

---

# âš– Bias & Variance Analysis  

|       Model         |       Bias       |            Variance              |
|---------------------|------------------|----------------------------------|
| Naive Bayes         | High Bias        |           Low Variance           |
| Logistic Regression | Moderate         |            Moderate              |
| Linear SVM          | Low Bias         |      Slightly Higher Variance    |
| Hard Voting         | Reduced Variance |          Moderate Bias           |
| Stacking            | Balanced         |         Reduced Variance         |
| AdaBoost            | Low Bias         | Can increase variance if overfit |

Stacking achieves the best bias-variance tradeoff.

---

# â–¶ Step-by-Step Execution  

## Step 1  
Install required libraries (if using Colab)

## Step 2  
Run the script

## Step 3  
Check generated files

---

# ğŸ“ Notes  

- Stratified K-Fold ensures balanced spam/ham distribution.  
- AdaBoost uses decision stumps (max_depth=1) as required.  
- TF-IDF improves text feature representation.  
- Stacking uses Logistic Regression as meta-learner.  

---

# ğŸ“ Viva-Voce Key Points  

1. Why use TF-IDF instead of CountVectorizer?  
   â†’ TF-IDF reduces importance of common words.

2. Difference between Hard and Soft Voting?  
   â†’ Hard uses majority voting; Soft uses probability averaging.

3. What is a Decision Stump?  
   â†’ A decision tree with depth = 1.

4. Why Stratified K-Fold?  
   â†’ Maintains class balance in each fold.

5. Why Stacking performed best?  
   â†’ Meta-learner learns optimal combination of base models.

6. How does AdaBoost work?  
   â†’ Sequentially focuses on misclassified samples.

---

# ğŸ Conclusion  

This project demonstrates that ensemble methods significantly improve spam classification performance.

Among all combining strategies, **Stacking Classifier** achieved the best balance between bias and variance and delivered the highest F1-score and ROC-AUC.

Therefore, stacking is recommended for production-level SMS spam filtering systems.

---

# ğŸ”— Project & Dataset Links  

**Google Colab Notebook**: ğŸ‘‰[https://colab.research.google.com/drive/14Bf7eai2Bk16McOK-TKvkXsUv23d9PU5#scrollTo=OOGw3mUb1oHr] 

**Dataset Link**:ğŸ‘‰[https://archive.ics.uci.edu/dataset/228/sms+spam+collection] 

---

# ğŸ™ Acknowledgement  

We thank the UCI Machine Learning Repository for providing the SMS Spam Collection dataset for academic use.
We also acknowledge the developers of Scikit-learn for providing powerful machine learning tools.

---
